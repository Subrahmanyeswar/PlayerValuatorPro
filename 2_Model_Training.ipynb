{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bbc4f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Successfully loaded 'final_data.csv'\n",
      "âœ… Column names cleaned.\n",
      "Prepared 10587 clean data points for training.\n",
      "Data split into 8469 training samples and 2118 testing samples.\n",
      "\n",
      "ðŸ’ª Training the XGBoost model...\n",
      "âœ… Model training complete!\n",
      "The model's average prediction error (RMSE) is: â‚¬ 7,396,774\n",
      "\n",
      "âœ… Final model saved to 'valuation_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- 1. Load the Dataset ---\n",
    "try:\n",
    "    df = pd.read_csv('final_data.csv')\n",
    "    print(\"âœ… Successfully loaded 'final_data.csv'\")\n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ 'final_data.csv' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- 2. Clean Column Names ---\n",
    "df.columns = df.columns.str.strip()\n",
    "print(\"âœ… Column names cleaned.\")\n",
    "\n",
    "# --- 3. Feature Selection & Data Cleaning ---\n",
    "features = [\n",
    "    'age', 'height', 'appearance', 'goals', 'assists', \n",
    "    'yellow cards', 'red cards', 'goals conceded', 'clean sheets', \n",
    "    'minutes played', 'days_injured', 'games_injured'\n",
    "]\n",
    "# --- THIS LINE IS NOW FIXED ---\n",
    "target = 'current_value'\n",
    "\n",
    "# Create a clean dataframe for training, ensuring all selected columns exist\n",
    "df_model = df[features + [target]].copy()\n",
    "df_model.dropna(inplace=True)\n",
    "df_model = df_model[df_model['current_value'] > 0] # Use the correct column name here too\n",
    "\n",
    "print(f\"Prepared {len(df_model)} clean data points for training.\")\n",
    "\n",
    "# --- 4. Split Data for Training and Testing ---\n",
    "X = df_model[features]\n",
    "y = df_model[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Data split into {len(X_train)} training samples and {len(X_test)} testing samples.\")\n",
    "\n",
    "# --- 5. Train the XGBoost Model ---\n",
    "print(\"\\nðŸ’ª Training the XGBoost model...\")\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror', n_estimators=1000, learning_rate=0.05,\n",
    "    early_stopping_rounds=10, eval_metric='rmse', n_jobs=-1\n",
    ")\n",
    "xgbr.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "# --- 6. Evaluate the Model's Performance ---\n",
    "predictions = xgbr.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f\"âœ… Model training complete!\")\n",
    "print(f\"The model's average prediction error (RMSE) is: â‚¬ {rmse:,.0f}\")\n",
    "\n",
    "# --- 7. Save the Trained Model ---\n",
    "joblib.dump(xgbr, 'valuation_model.joblib')\n",
    "print(\"\\nâœ… Final model saved to 'valuation_model.joblib'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
